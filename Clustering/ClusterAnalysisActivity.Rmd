---
title: "Cluster Analysis for Wholesale Customer Segmentation"
author: "Haroon Ahmed"
date: "9 July 2017"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float: yes
---

**NOTE** Before starting this assignment please remember to clear your environment, you can do that by running the following code chunk

```{r}

rm(list = ls(all=TRUE))

```

# Agenda

* Get the data

* Data pre-processing

* Explore the data

* Hierarchical Clustering

* Kmeans Clustering

* Visualising Clusters and Evaluation


# Problem Description

* In the following Unsupervised Learning activity, you will perform cluster analysis on a dataset that has arrests per 100,000 residents for assault, murder, and rape in each of the 50 US states

* The variable names in the dataset are self explanatory

* So, you will cluster US states based on the crime rates, which can then be passed on to public policy experts to gain insight from it


# Reading & Understanding the Data

* Read in the dataset

```{r}

# Use the setwd() function to get to the directory where the data is present

crime_data <- read.csv("C:\\MOOC\\Machine Learning\\Clustering\\crime_data.csv")

```

* Use the str() and summary() functions to get a feel for the dataset.

```{r}

str(crime_data)
summary(crime_data)

```

* Take a look at the data using the "head()" and "tail()" functions

```{r}

head(crime_data)
tail(crime_data)

```

# Data pre-processing

* Check for the number of missing values in the dataset

```{r}

sum(is.na(crime_data))

```


* Convert the State names into row names and remove that variable from the dataset

```{r}

rownames(crime_data) <- crime_data$State
crime_data <- crime_data[, !(colnames(crime_data) %in% "State")]

```

* Standardize and scale the data

```{r}

crime_data <- scale(crime_data, center = T, scale = T)
```

# Data exploration

* Visualise the distances between the individual observations using the fviz_dist()

```{r, fig.width=12, fig.height=8}

library(factoextra)
distance <- get_dist(crime_data)
fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))

```

# Hierarchical Clustering

* Cluster the data using the Ward algorithm

```{r}

dist <- dist(crime_data, method = "euclidean")
hc_fit <- hclust(dist, method = "ward.D2")


```

* Plot the dendogram for hierarchical clustering

```{r, fig.height=5, fig.width=10}

plot(hc_fit)

```

* Cut the tree to 4 clusters

```{r}

points_hc <- cutree(hc_fit, k = 4)
crime_clusts_hc <- cbind(points_hc, crime_data)
head(crime_clusts_hc)
colnames(crime_clusts_hc)[1] <- "cluster_hc"

```

* Plot a new dendogram, with each of the clusters being surrounded by a border, using the rect.hclust() function

```{r, fig.height=5, fig.width=10}

plot(hc_fit)
rect.hclust(hc_fit, k = 4, border = "red")

```


# K-Means Clustering

* Build a basic kmeans model with k = 2

```{r}

km_basic <- kmeans(crime_data, centers = 2)
str(km_basic)

```

* Build a scree plot and choose a "k"

```{r}

wss <- 0

for (i in 1:10) {
  cfit = kmeans(crime_data, centers = i)
  wss[i] <- sum(cfit$withinss)
}

set.seed(123)
fviz_nbclust(crime_data, kmeans, method = "wss")


```

* Choose a k and cluster the data

```{r}

# We can choose a k = 4, 5 or 6

km_clust <- kmeans(crime_data, 4)
km_points <- km_clust$cluster
crime_clusts_km <- as.data.frame(cbind(km_clust$cluster, crime_data))
colnames(crime_clusts_km)[1] <- "cluster_km"
head(crime_clusts_km)

```

* Visualise the clusters by plotting the data points on the first two principal components

```{r, fig.height=5, fig.width=8}

fviz_cluster(km_clust, crime_data)

```


# Evaluation of Cluster Similarity


* Evaluate the cluster stability using the adjustedRandIndex() function from the mclust package

* Extract 75% of the data

```{r}

set.seed(1234)
sample_rows <- sample(1:nrow(crime_data), 0.80*nrow(crime_data))
extracted_obs <- crime_data[sample_rows, ]

```

* Let's build a kmeans clustering with k = 6

```{r}

km_extr <- kmeans(extracted_obs, 4)

```

* Now using the adjustedRandIndex() function, we can get a measure of the cluster stability

```{r}

library(mclust)
adjustedRandIndex(km_clust$cluster[sample_rows], km_extr$cluster)

```





















